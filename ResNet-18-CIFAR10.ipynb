{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet for CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training params\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "data_augmentation = False\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CIFAR 10 and do data arrangment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (50000, 32, 32, 3)\n",
      "x_test shpae:  (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize the pixel value between 0-1 to speed-up training\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "# mean center (with the train mean)\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train -= x_train_mean\n",
    "x_test -= x_train_mean\n",
    "\n",
    "# trace\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('x_test shpae: ', x_test.shape)\n",
    "\n",
    "# one-hot for the class label\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape= x_train.shape[1:] # (32,32,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    '''\n",
    "    learning rate which adjust based on epoch\n",
    "    Init with larger learning rate, decreasing while epoch increasing\n",
    "    '''\n",
    "    lr = 1e-3 # 0.001\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    \n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=(1,1),\n",
    "                 activation='relu',\n",
    "                 batch_normalization = True,\n",
    "                 conv_first = True):  # ResNet v1: conv_bn_acti / ResNet v2: batch_acti_conv\n",
    "    '''\n",
    "    Helper function for building ResNet\n",
    "    '''\n",
    "    \n",
    "    # keras-conv2d\n",
    "    conv = Conv2D(filters=num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',  # TODO: understand what is this\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "    \n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)  # conv at the beginning\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x) # conv at the end\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper restnet 20\n",
    "def resnet_v1(input_shape,\n",
    "              depth, \n",
    "              num_classes=10):\n",
    "    '''\n",
    "    Conv-BN-Relu\n",
    "    \n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-Relu\n",
    "    Last Relu is after the shortcut connection.\n",
    "    \n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by stride 2 conv layer, while the filter number doubled.\n",
    "    \n",
    "    \n",
    "    Stage    Feature map size  Filter number\n",
    "    --------|-----------------|-------------\n",
    "    stage 0:        32x32            16\n",
    "    stage 1:        16x16            32\n",
    "    stage 2:         8x8             64\n",
    "    '''\n",
    "    # Assertion\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n2 e.g. 20, 32, 44')\n",
    "    \n",
    "    # Start construct models\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # first layer\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    \n",
    "    # recursively stack up of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if(stage > 0 and res_block == 0): # Except from first stage, the other stage, first block need to downsample\n",
    "                strides = 2  # down-sampling\n",
    "            \n",
    "            l1 = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)  # only the l1 needs to consider stride\n",
    "                                               # only the l1 needs activation\n",
    "            l2 = resnet_layer(inputs=l1,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)  # l2 does not need activation\n",
    "            \n",
    "            if(stage > 0 and res_block == 0): # When downsampling, need to make sure the shortcut dimension is aligned\n",
    "                # handling the dimension for the input -> 1x1 conv, not bn! no activation!!!\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1, # 1x1 conv, just change the depth\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            \n",
    "            # short-cut connect!\n",
    "            x = keras.layers.add([l2,x]) \n",
    "            x = Activation('relu')(x)\n",
    "        \n",
    "        num_filters *= 2  # filter size doulbe for each stage\n",
    "    \n",
    "    \n",
    "    # V1 does not use BN after last shortcut connection-Relu\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    flat_x = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax', \n",
    "                    kernel_initializer='he_normal')(flat_x)\n",
    "    \n",
    "    # Model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet 18\n",
    "def resnet_v1_18(input_shape,\n",
    "                 num_classes=10):\n",
    "    '''\n",
    "    Conv-BN-Relu\n",
    "    \n",
    "    Stacks of Stage and res_block\n",
    "    Last Relu is after the shortcut connection.\n",
    "    \n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by stride 2 conv layer, while the filter number doubled.\n",
    "    \n",
    "    \n",
    "    Stage    Feature map size  Filter number\n",
    "    --------|-----------------|-------------\n",
    "    stage 0:        32x32            64\n",
    "    stage 1:        16x16           128\n",
    "    stage 2:          8x8           256\n",
    "    stage 3:          4x4           512\n",
    "    '''\n",
    "    num_filters = 64 \n",
    "    num_res_blocks = 2\n",
    "    num_stages = 4\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # first layer (32x32x64)\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=64)\n",
    "    \n",
    "    for stage in range(num_stages):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = (1,1)\n",
    "            \n",
    "            if(stage > 0 and res_block == 0): # Except the first stage, when meet first res_block, need to down-sammpling\n",
    "                strides = (2,2)\n",
    "                print('Down-sampling')\n",
    "            \n",
    "            l1 = resnet_layer(inputs=x,\n",
    "                              num_filters=num_filters,\n",
    "                              strides=strides) # only the first layer need to worry about strides\n",
    "            \n",
    "            l2 = resnet_layer(inputs=l1,\n",
    "                              num_filters=num_filters,\n",
    "                              activation=None) # relu will happen after adding shortcut\n",
    "            \n",
    "            if(stage > 0 and res_block == 0): # Except the first stage, when meet first res_block, need to handling the dimension change (H,W and Depth!!!)\n",
    "                # over-write x\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1, # 1x1 conv  -> depth change\n",
    "                                 strides=strides, # 2x2 strides -> H,W change\n",
    "                                 activation=None, # relu will happend after adding shortcut \n",
    "                                 batch_normalization=False) \n",
    "            print('Stage: {}, block: {}, l2 shape {}, x shape {}'.format(stage, res_block, l2.shape[1:], x.shape[1:]))\n",
    "            \n",
    "            # adding short-cut, over-write x for the new loop\n",
    "            x = keras.layers.add([l2,x])\n",
    "            x = Activation('relu')(x) # now activation\n",
    "            \n",
    "        num_filters *= 2 # increment filter size after each stage\n",
    "    \n",
    "    # layer 17 (4x4x512)\n",
    "    # final_layer 18 (1x1x512)\n",
    "    x = AveragePooling2D(pool_size=4)(x)\n",
    "    flat_x = Flatten()(x)\n",
    "    \n",
    "    # output\n",
    "    output = Dense(units=num_classes,\n",
    "                   activation='softmax',\n",
    "                   kernel_initializer='he_normal')(flat_x)\n",
    "    \n",
    "    # Model\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: 0, block: 0, l2 shape (32, 32, 64), x shape (32, 32, 64)\n",
      "Stage: 0, block: 1, l2 shape (32, 32, 64), x shape (32, 32, 64)\n",
      "Down-sampling\n",
      "Stage: 1, block: 0, l2 shape (16, 16, 128), x shape (16, 16, 128)\n",
      "Stage: 1, block: 1, l2 shape (16, 16, 128), x shape (16, 16, 128)\n",
      "Down-sampling\n",
      "Stage: 2, block: 0, l2 shape (8, 8, 256), x shape (8, 8, 256)\n",
      "Stage: 2, block: 1, l2 shape (8, 8, 256), x shape (8, 8, 256)\n",
      "Down-sampling\n",
      "Stage: 3, block: 0, l2 shape (4, 4, 512), x shape (4, 4, 512)\n",
      "Stage: 3, block: 1, l2 shape (4, 4, 512), x shape (4, 4, 512)\n"
     ]
    }
   ],
   "source": [
    "model = resnet_v1_18(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 128)  73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  8320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 128)  0           batch_normalization_7[0][0]      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 128)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           batch_normalization_9[0][0]      \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 256)    295168      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 256)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 256)    590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 256)    1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 256)    33024       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 256)    0           batch_normalization_11[0][0]     \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 256)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 256)    590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 256)    590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 256)    0           batch_normalization_13[0][0]     \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 256)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 512)    1180160     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 512)    2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 512)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 512)    2359808     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 512)    2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 512)    131584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 4, 512)    0           batch_normalization_15[0][0]     \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 512)    2359808     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 512)    2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 512)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 512)    2359808     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 512)    2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 512)    0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 512)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           5130        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,184,778\n",
      "Trainable params: 11,176,970\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=lr_schedule(0)), # first epoch\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dir\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name='cifar10-model-resenet18'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedis(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 1.9983 - accuracy: 0.5596 - val_loss: 1.5048 - val_accuracy: 0.6800\n",
      "Epoch 2/50\n",
      "Learning rate:  0.001\n",
      "   96/50000 [..............................] - ETA: 1:37 - loss: 1.2652 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 94s 2ms/step - loss: 1.3175 - accuracy: 0.7267 - val_loss: 1.5334 - val_accuracy: 0.6501\n",
      "Epoch 3/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 1.1355 - accuracy: 0.7732 - val_loss: 1.3732 - val_accuracy: 0.6927\n",
      "Epoch 4/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 1.0323 - accuracy: 0.8011 - val_loss: 1.3302 - val_accuracy: 0.7165\n",
      "Epoch 5/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.9542 - accuracy: 0.8254 - val_loss: 1.1054 - val_accuracy: 0.7752\n",
      "Epoch 6/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.8826 - accuracy: 0.8466 - val_loss: 1.2245 - val_accuracy: 0.7467\n",
      "Epoch 7/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.8313 - accuracy: 0.8630 - val_loss: 1.3207 - val_accuracy: 0.7333\n",
      "Epoch 8/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 0.7905 - accuracy: 0.8752 - val_loss: 0.9835 - val_accuracy: 0.8159\n",
      "Epoch 9/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.7525 - accuracy: 0.8873 - val_loss: 1.0695 - val_accuracy: 0.8079\n",
      "Epoch 10/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.7217 - accuracy: 0.8983 - val_loss: 1.1600 - val_accuracy: 0.7798\n",
      "Epoch 11/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6934 - accuracy: 0.9071 - val_loss: 0.9944 - val_accuracy: 0.8206\n",
      "Epoch 12/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6653 - accuracy: 0.9162 - val_loss: 1.0092 - val_accuracy: 0.8201\n",
      "Epoch 13/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6484 - accuracy: 0.9210 - val_loss: 0.9532 - val_accuracy: 0.8292\n",
      "Epoch 14/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6304 - accuracy: 0.9262 - val_loss: 1.0311 - val_accuracy: 0.8215\n",
      "Epoch 15/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6170 - accuracy: 0.9306 - val_loss: 1.0800 - val_accuracy: 0.8149\n",
      "Epoch 16/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6056 - accuracy: 0.9345 - val_loss: 0.9746 - val_accuracy: 0.8317\n",
      "Epoch 17/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5897 - accuracy: 0.9379 - val_loss: 1.0033 - val_accuracy: 0.8311\n",
      "Epoch 18/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5807 - accuracy: 0.9402 - val_loss: 1.2589 - val_accuracy: 0.7805\n",
      "Epoch 19/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5702 - accuracy: 0.9424 - val_loss: 1.1235 - val_accuracy: 0.8009\n",
      "Epoch 20/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5584 - accuracy: 0.9451 - val_loss: 1.1327 - val_accuracy: 0.8057\n",
      "Epoch 21/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5575 - accuracy: 0.9447 - val_loss: 0.9765 - val_accuracy: 0.8286\n",
      "Epoch 22/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5437 - accuracy: 0.9482 - val_loss: 1.0305 - val_accuracy: 0.8218\n",
      "Epoch 23/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5373 - accuracy: 0.9482 - val_loss: 1.0651 - val_accuracy: 0.8155\n",
      "Epoch 24/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5353 - accuracy: 0.9494 - val_loss: 1.0249 - val_accuracy: 0.8169\n",
      "Epoch 25/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5230 - accuracy: 0.9529 - val_loss: 1.0028 - val_accuracy: 0.8326\n",
      "Epoch 26/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5179 - accuracy: 0.9533 - val_loss: 1.2173 - val_accuracy: 0.7883\n",
      "Epoch 27/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5189 - accuracy: 0.9528 - val_loss: 1.1490 - val_accuracy: 0.8116\n",
      "Epoch 28/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5086 - accuracy: 0.9554 - val_loss: 1.0733 - val_accuracy: 0.8089\n",
      "Epoch 29/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5087 - accuracy: 0.9541 - val_loss: 1.0676 - val_accuracy: 0.8008\n",
      "Epoch 30/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5043 - accuracy: 0.9545 - val_loss: 1.0038 - val_accuracy: 0.8352\n",
      "Epoch 31/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.5003 - accuracy: 0.9552 - val_loss: 1.0156 - val_accuracy: 0.8292\n",
      "Epoch 32/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4952 - accuracy: 0.9565 - val_loss: 1.0774 - val_accuracy: 0.8125\n",
      "Epoch 33/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4937 - accuracy: 0.9560 - val_loss: 1.0289 - val_accuracy: 0.8206\n",
      "Epoch 34/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4873 - accuracy: 0.9568 - val_loss: 1.1174 - val_accuracy: 0.8019\n",
      "Epoch 35/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4824 - accuracy: 0.9585 - val_loss: 0.9874 - val_accuracy: 0.8286\n",
      "Epoch 36/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4819 - accuracy: 0.9576 - val_loss: 1.0054 - val_accuracy: 0.8302\n",
      "Epoch 37/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4748 - accuracy: 0.9594 - val_loss: 0.9609 - val_accuracy: 0.8403\n",
      "Epoch 38/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4703 - accuracy: 0.9593 - val_loss: 1.0196 - val_accuracy: 0.8305\n",
      "Epoch 39/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4756 - accuracy: 0.9572 - val_loss: 1.0191 - val_accuracy: 0.8212\n",
      "Epoch 40/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4674 - accuracy: 0.9608 - val_loss: 1.1283 - val_accuracy: 0.8068\n",
      "Epoch 41/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4615 - accuracy: 0.9604 - val_loss: 1.0470 - val_accuracy: 0.8238\n",
      "Epoch 42/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4594 - accuracy: 0.9606 - val_loss: 1.1925 - val_accuracy: 0.7984\n",
      "Epoch 43/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4526 - accuracy: 0.9627 - val_loss: 1.0602 - val_accuracy: 0.8185\n",
      "Epoch 44/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4544 - accuracy: 0.9602 - val_loss: 1.1366 - val_accuracy: 0.8087\n",
      "Epoch 45/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4540 - accuracy: 0.9598 - val_loss: 0.9409 - val_accuracy: 0.8343\n",
      "Epoch 46/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4466 - accuracy: 0.9621 - val_loss: 1.0055 - val_accuracy: 0.8221\n",
      "Epoch 47/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4465 - accuracy: 0.9624 - val_loss: 0.9568 - val_accuracy: 0.8401\n",
      "Epoch 48/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4480 - accuracy: 0.9604 - val_loss: 0.9943 - val_accuracy: 0.8330\n",
      "Epoch 49/50\n",
      "Learning rate:  0.001\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.4366 - accuracy: 0.9639 - val_loss: 0.9915 - val_accuracy: 0.8208\n",
      "Epoch 50/50\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 85s 2ms/step - loss: 0.4394 - accuracy: 0.9621 - val_loss: 1.1107 - val_accuracy: 0.7954\n",
      "10000/10000 [==============================] - 5s 510us/step\n",
      "Test loss: 1.1106641494750977\n",
      "Test accuracy: 0.7954000234603882\n"
     ]
    }
   ],
   "source": [
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
